{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "MNIST_dir = \"MNIST_h5/60000.h5\" #MNIST training images in hdf5 format relative file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5(filepath):\n",
    "    '''Reads MNIST training images and labels from the hdf5 file.\n",
    "       Parameter\n",
    "       ---------\n",
    "       filepath : Path to the .h5 file | string\n",
    "    '''\n",
    "    file   = h5py.File(filepath, \"r+\") #open the hdf5 file\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\") #read the images dataset\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")   #read the labels dataset (stored as meta)\n",
    "    \n",
    "    return (images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_h5(MNIST_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(label_arr):\n",
    "    '''Returns the given MNIST labels from np arrays of integers to np array of one hot labels.\n",
    "       Parameter\n",
    "       ---------\n",
    "       label_arr : np array of MNIST integer labels\n",
    "    '''\n",
    "    total_labels  = label_arr.shape[0] #get the total number of labels\n",
    "    one_hot_label = np.zeros([total_labels, 10]) #10 for num of classes in MNIST\n",
    "    \n",
    "    for i in range(label_arr.shape[0]): #loop through all the labels\n",
    "        \n",
    "        one_hot_label[i][int(label_arr[i])] = 1.0 #the label value will be marked as 1.0 at that specific index\n",
    "        \n",
    "    return one_hot_label #returns the np one-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = one_hot_encoder(labels) #fetch the one-hot encoded labels\n",
    "images = images.reshape(images.shape[0], 28,28,1) #images in numpy : [60000, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size           = 100\n",
    "learning_rate        = 1e-3\n",
    "epsilon              = 1e-10\n",
    "epoch                = 5\n",
    "height,width         = 28, 28\n",
    "num_labels           = 10\n",
    "primary_caps_vlength = 8\n",
    "digit_caps_vlength   = 16\n",
    "routing_iteration    = 3\n",
    "m_plus               = 0.9\n",
    "m_minus              = 0.1\n",
    "lambda_              = 0.5\n",
    "reg_scale            = 0.392\n",
    "reconstruction       = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capsule Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(capsule):\n",
    "    '''Note that the input is a [batch_size, 1152, 1, 8, 1] tensor. \n",
    "       I.e. there are 1152 8-d vectors in each batch.\n",
    "       To squash the vectors, we specificy the dimension the vector is in. In this case, axis is -2.\n",
    "    '''\n",
    "    #The output vector is in dimension -2 \n",
    "    dot_product = tf.reduce_sum(tf.square(capsule), axis=-2, keepdims=True) \n",
    "    scalar_factor = dot_product/(1 + dot_product)/tf.sqrt(dot_product + epsilon)\n",
    "    vec_squashed = scalar_factor * capsule\n",
    "    return vec_squashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing(capsule_layer, num_capsules):\n",
    "    \n",
    "    #define a weight variable for one capsule first\n",
    "    W = tf.get_variable('Weight', shape=(1, num_capsules, num_labels, primary_caps_vlength, digit_caps_vlength))\n",
    "    b = tf.get_variable('Bias', shape=(1,1,num_labels, digit_caps_vlength,1 )) \n",
    "    W = tf.tile(W, [tf.shape(capsule_layer)[0], 1, 1 ,1 ,1]) #tiling just makes a copy of the same weight variable for all the items in the batch. It is still the same weight.\n",
    "    x = tf.tile(capsule_layer, [1, 1, num_labels, 1, 1]) #this is set up for dynamic routing later\n",
    "    u_hat = tf.matmul(W,x, transpose_a=True) #[batch_size, 1152, 10, 16, 1]\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stopped_gradient')\n",
    "    \n",
    "    #coefficients for dynamic routing\n",
    "    #MUST be initialized to zero for every round\n",
    "    b_ij = tf.zeros([tf.shape(capsule_layer)[0], num_capsules, num_labels, 1, 1], dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    for r_iter in range(routing_iteration):\n",
    "        \n",
    "        #softmax so that the value of the coefficient is between 0 and 1\n",
    "        #lower level capsules that contribute the most to a particular higher level capsule\n",
    "        #will have the largest value\n",
    "        c_ij = tf.nn.softmax(b_ij, axis=2)\n",
    "        \n",
    "        #last iteration\n",
    "        if r_iter == routing_iteration - 1:\n",
    "            \n",
    "            s_j = tf.multiply(c_ij, u_hat) #multiply the coefficients with each capsule\n",
    "            \n",
    "            #reducing the sum at axis 1 makes the capsules with highest coefficient to \n",
    "            #contribute more and the lowest coefficient capsules to contirbute less\n",
    "            s_j = tf.reduce_sum(s_j, axis=1, keepdims=True) + b\n",
    "            \n",
    "            v_j = squash(s_j)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            s_j = tf.multiply(c_ij, u_hat_stopped)\n",
    "            \n",
    "            #reducing the sum at axis 1 makes the capsules with highest coefficient to contribute more and the \n",
    "            #lowest coefficient capsules to contirbute less\n",
    "            s_j = tf.reduce_sum(s_j, axis=1, keepdims=True) + b \n",
    "            v_j = squash(s_j)\n",
    "            \n",
    "            #make a copy at the number of capsules axis in\n",
    "            #order to find the scalar product\n",
    "            v_j_tiled = tf.tile(v_j, [1, num_capsules, 1, 1, 1]) \n",
    "            \n",
    "            product = u_hat_stopped * v_j_tiled #[batch_size, 1152, 10, 16, 1]\n",
    "            #by reducing the sum at axis 3, where the previous product produced new vectors, gives a scalar value.\n",
    "            #Whichever capsules that agrees with each other will produce high valued vectors. Sum reduce would\n",
    "            #add them all up together to bring a scalar value which then used for the softmax to enable the routing\n",
    "            u_produce_v = tf.reduce_sum(product, axis=3, keepdims=True) #\n",
    "            \n",
    "            #append the contribution of each lower level capsules to the higher level capsules\n",
    "            b_ij += u_produce_v\n",
    "    \n",
    "    return v_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, height, width, 1))\n",
    "Y = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "\n",
    "conv1 = tf.contrib.layers.conv2d(X, num_outputs=256, kernel_size=9, stride=1, padding='VALID', \n",
    "                                 activation_fn=tf.nn.relu) #output conv1 : [batch_size, 20, 20, 1]\n",
    "conv2 = tf.contrib.layers.conv2d(conv1, num_outputs=256, kernel_size=9, stride=2, padding='VALID',\n",
    "                                 activation_fn=tf.nn.relu) #output conv2 : [batch_size, 6, 6, 1]\n",
    "\n",
    "#reshape the output of conv2 to [batch_size, 1152, 8, 1]\n",
    "capsules = tf.reshape(conv2, (tf.shape(conv2)[0], -1, primary_caps_vlength, 1))\n",
    "num_capsules = 6*6*32 #= 1152\n",
    "primary_caps = squash(capsules) #non-linearity\n",
    "\n",
    "#each primary capsule is multiplied by a weight matrix.The weight matrix will change the 8-D vectors\n",
    "#to 16-D vectors. Furthermore, the number of capsules should also be reduced to 10.We would do that by dynamic \n",
    "#routing.\n",
    "#However, before that, we need to create an extra rank after the num of capsules and tile it (2nd index\n",
    "#starting from index 0) to 10. With that, the 1024 capsules can be reduced to 1 and remove that dimension. \n",
    "#The process of reducing the capsules to 10 is done by dynamic routing.\n",
    "primary_caps = tf.reshape(primary_caps, shape=(tf.shape(capsules)[0], -1, 1, 8, 1 )) #create the extra rank \n",
    "#primary_caps.shape = [batch_size, 1152, 1, 8, 1]\n",
    "\n",
    "digits = routing(primary_caps, num_capsules) # [batch_size, 1, 10, 16, 1]\n",
    "digits = tf.squeeze(digits, axis=1) # [batch_size, 10, 16, 1]\n",
    "\n",
    "#the length of each vectors in the digit capsule layer\n",
    "v_lengths = tf.sqrt(tf.reduce_sum(tf.square(digits), axis=2, keepdims=True) + epsilon) #[batch_size, 10, 1, 1]\n",
    "\n",
    "#Objective function for classification\n",
    "max_l = tf.square(tf.maximum(0., m_plus - v_lengths))\n",
    "max_r = tf.square(tf.maximum(0., v_lengths - m_minus))\n",
    "\n",
    "max_l = tf.reshape(max_l, shape=(tf.shape(digits)[0], -1))\n",
    "max_r = tf.reshape(max_r, shape=(tf.shape(digits)[0], -1))\n",
    "T_c = Y\n",
    "\n",
    "L_c = T_c * max_l + lambda_*(1-T_c)*max_r\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1)) #test without reduce mean later\n",
    "\n",
    "\n",
    "#RECONSTRUCTION\n",
    "#First step is to mask out all the vectors from digit capsules except the correct class vector.\n",
    "#By performing an element-wise multiplication between the 10 capsules and the Y vector\n",
    "mask = tf.multiply(tf.squeeze(digits), tf.reshape(Y, (-1, num_labels, 1)))\n",
    "vector_j = tf.reshape(mask, shape=(tf.shape(digits)[0], 160)) #reshape into [batch_size, 160]\n",
    "fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "decoded = tf.contrib.layers.fully_connected(fc2, num_outputs=height*width*1, activation_fn=tf.sigmoid)\n",
    "\n",
    "#RECONSTUCTION LOSS\n",
    "origin   = tf.reshape(X, shape=(tf.shape(digits)[0], -1))\n",
    "squared  = tf.square(decoded - origin)\n",
    "reconst_err = tf.reduce_mean(squared)\n",
    "\n",
    "total_loss = margin_loss + reg_scale + reconst_err #total for both classification and reconstruction\n",
    "\n",
    "optimizer_classification = tf.train.AdamOptimizer(learning_rate).minimize(margin_loss) #for classification\n",
    "optimizer_decoder = tf.train.AdamOptimizer(learning_rate).minimize(total_loss) #for reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss at epoch 0 is 0.0498201\n",
      "The loss at epoch 1 is 0.0189173\n",
      "The loss at epoch 2 is 0.0167735\n",
      "The loss at epoch 3 is 0.0193796\n",
      "The loss at epoch 4 is 0.017869\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_images = images.shape[0] #total number of training images\n",
    "\n",
    "for epoch_iter in range(epoch):\n",
    "    counter = 0\n",
    "    loss = 0\n",
    "    \n",
    "    for index in range(0, total_images, batch_size):\n",
    "        \n",
    "        end_batch = index + batch_size \n",
    "        \n",
    "        if end_batch >= total_images : end_batch = None #to prevent the last index to go beyond the data size\n",
    "        \n",
    "        if reconstruction:\n",
    "            #optimize for classification and reconstruction\n",
    "            loss += sess.run([total_loss, optimizer_decoder], \n",
    "                            feed_dict={X:images[index:end_batch], Y:labels[index:end_batch]})[0] #loss is at [0]\n",
    "            counter += 1\n",
    "            \n",
    "        else:\n",
    "            #optimize only for classification\n",
    "            loss += sess.run([margin_loss, optimizer_classification], \n",
    "                            feed_dict={X:images[index:end_batch], Y:labels[index:end_batch]})[0] #loss is at [0]\n",
    "            counter += 1\n",
    "    \n",
    "    print(\"The loss at epoch %d is %g\"%(epoch_iter, loss/counter))\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa",
   "language": "python",
   "name": "nasa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
