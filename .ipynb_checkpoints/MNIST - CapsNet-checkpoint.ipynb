{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "train_MNIST_dir = \"MNIST_h5/training_data.h5\" #MNIST training images in hdf5 format relative file path\n",
    "test_MNIST_dir = \"MNIST_h5/testing_data.h5\"#MNIST testing images in hdf5 format relative file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_h5(filepath):\n",
    "    '''Reads MNIST training images and labels from the hdf5 file.\n",
    "       Parameter\n",
    "       ---------\n",
    "       filepath : Path to the .h5 file | string\n",
    "    '''\n",
    "    file   = h5py.File(filepath, \"r+\") #open the hdf5 file\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\") #read the images dataset\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")   #read the labels dataset (stored as meta)\n",
    "    \n",
    "    return (images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_h5(train_MNIST_dir)\n",
    "test_images, test_labels = read_h5(test_MNIST_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(label_arr):\n",
    "    '''Returns the given MNIST labels from np arrays of integers to np array of one hot labels.\n",
    "       Parameter\n",
    "       ---------\n",
    "       label_arr : np array of MNIST integer labels\n",
    "    '''\n",
    "    total_labels  = label_arr.shape[0] #get the total number of labels\n",
    "    one_hot_label = np.zeros([total_labels, 10]) #10 for num of classes in MNIST\n",
    "    \n",
    "    for i in range(label_arr.shape[0]): #loop through all the labels\n",
    "        \n",
    "        one_hot_label[i][int(label_arr[i])] = 1.0 #the label value will be marked as 1.0 at that specific index\n",
    "        \n",
    "    return one_hot_label #returns the np one-hot label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = one_hot_encoder(labels) #fetch the one-hot encoded labels\n",
    "images = images.reshape(images.shape[0], 28,28,1) #images in numpy : [60000, 28, 28, 1]\n",
    "\n",
    "test_labels = one_hot_encoder(test_labels)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size           = 50\n",
    "learning_rate        = 1e-4\n",
    "epsilon              = 1e-9\n",
    "epoch                = 20\n",
    "height,width         = 28, 28\n",
    "num_labels           = 10\n",
    "primary_caps_vlength = 8\n",
    "digit_caps_vlength   = 16\n",
    "routing_iteration    = 3\n",
    "m_plus               = 0.9\n",
    "m_minus              = 0.1\n",
    "lambda_              = 0.5\n",
    "reg_scale            = 0.392\n",
    "reconstruction       = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capsule Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(capsule):\n",
    "    '''Note that the input is a [batch_size, 1152, 1, 8, 1] tensor. \n",
    "       I.e. there are 1152 8-d vectors in each batch.\n",
    "       To squash the vectors, we specificy the dimension the vector is in. In this case, axis is -2.\n",
    "    '''\n",
    "    #The output vector is in dimension -2 \n",
    "    dot_product = tf.reduce_sum(tf.square(capsule), axis=-2, keepdims=True) \n",
    "    scalar_factor = dot_product/(1 + dot_product)/tf.sqrt(dot_product + epsilon)\n",
    "    vec_squashed = scalar_factor * capsule\n",
    "    return vec_squashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing(capsule_layer, num_capsules):\n",
    "    \n",
    "    #define a weight variable for one capsule first\n",
    "    W = tf.get_variable('Weight', shape=(1, num_capsules, num_labels, primary_caps_vlength, digit_caps_vlength))\n",
    "    b = tf.get_variable('Bias', shape=(1,1,num_labels, digit_caps_vlength,1 )) \n",
    "    W = tf.tile(W, [tf.shape(capsule_layer)[0], 1, 1 ,1 ,1]) #tiling just makes a copy of the same weight variable for all the items in the batch. It is still the same weight.\n",
    "    x = tf.tile(capsule_layer, [1, 1, num_labels, 1, 1]) #this is set up for dynamic routing later\n",
    "    u_hat = tf.matmul(W,x, transpose_a=True) #[batch_size, 1152, 10, 16, 1]\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stopped_gradient')\n",
    "    \n",
    "    #coefficients for dynamic routing\n",
    "    #MUST be initialized to zero for every round\n",
    "    b_ij = tf.zeros([tf.shape(capsule_layer)[0], num_capsules, num_labels, 1, 1], dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    for r_iter in range(routing_iteration):\n",
    "        \n",
    "        #softmax so that the value of the coefficient is between 0 and 1\n",
    "        #lower level capsules that contribute the most to a particular higher level capsule\n",
    "        #will have the largest value\n",
    "        c_ij = tf.nn.softmax(b_ij, axis=2)\n",
    "        \n",
    "        #last iteration\n",
    "        if r_iter == routing_iteration - 1:\n",
    "            \n",
    "            s_j = tf.multiply(c_ij, u_hat) #multiply the coefficients with each capsule\n",
    "            \n",
    "            #reducing the sum at axis 1 makes the capsules with highest coefficient to \n",
    "            #contribute more and the lowest coefficient capsules to contirbute less\n",
    "            s_j = tf.reduce_sum(s_j, axis=1, keepdims=True) + b\n",
    "            \n",
    "            v_j = squash(s_j)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            s_j = tf.multiply(c_ij, u_hat_stopped)\n",
    "            \n",
    "            #reducing the sum at axis 1 makes the capsules with highest coefficient to contribute more and the \n",
    "            #lowest coefficient capsules to contirbute less\n",
    "            s_j = tf.reduce_sum(s_j, axis=1, keepdims=True) + b \n",
    "            v_j = squash(s_j)\n",
    "            \n",
    "            #make a copy at the number of capsules axis in\n",
    "            #order to find the scalar product\n",
    "            v_j_tiled = tf.tile(v_j, [1, num_capsules, 1, 1, 1]) \n",
    "            \n",
    "            product = u_hat_stopped * v_j_tiled #[batch_size, 1152, 10, 16, 1]\n",
    "            #by reducing the sum at axis 3, where the previous product produced new vectors, gives a scalar value.\n",
    "            #Whichever capsules that agrees with each other will produce high valued vectors. Sum reduce would\n",
    "            #add them all up together to bring a scalar value which then used for the softmax to enable the routing\n",
    "            u_produce_v = tf.reduce_sum(product, axis=3, keepdims=True) #\n",
    "            \n",
    "            #append the contribution of each lower level capsules to the higher level capsules\n",
    "            b_ij += u_produce_v\n",
    "    \n",
    "    return v_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, height, width, 1))\n",
    "Y = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "\n",
    "conv1 = tf.contrib.layers.conv2d(X, num_outputs=256, kernel_size=9, stride=1, padding='VALID', \n",
    "                                 activation_fn=tf.nn.relu) #output conv1 : [batch_size, 20, 20, 1]\n",
    "conv2 = tf.contrib.layers.conv2d(conv1, num_outputs=256, kernel_size=9, stride=2, padding='VALID',\n",
    "                                 activation_fn=tf.nn.relu) #output conv2 : [batch_size, 6, 6, 1]\n",
    "\n",
    "#reshape the output of conv2 to [batch_size, 1152, 8, 1]\n",
    "capsules = tf.reshape(conv2, (tf.shape(conv2)[0], -1, primary_caps_vlength, 1))\n",
    "num_capsules = 6*6*32 #= 1152\n",
    "primary_caps = squash(capsules) #non-linearity\n",
    "\n",
    "#each primary capsule is multiplied by a weight matrix.The weight matrix will change the 8-D vectors\n",
    "#to 16-D vectors. Furthermore, the number of capsules should also be reduced to 10.We would do that by dynamic \n",
    "#routing.\n",
    "#However, before that, we need to create an extra rank after the num of capsules and tile it (2nd index\n",
    "#starting from index 0) to 10. With that, the 1024 capsules can be reduced to 1 and remove that dimension. \n",
    "#The process of reducing the capsules to 10 is done by dynamic routing.\n",
    "primary_caps = tf.reshape(primary_caps, shape=(tf.shape(capsules)[0], -1, 1, 8, 1 )) #create the extra rank \n",
    "#primary_caps.shape = [batch_size, 1152, 1, 8, 1]\n",
    "\n",
    "digits = routing(primary_caps, num_capsules) # [batch_size, 1, 10, 16, 1]\n",
    "digits = tf.squeeze(digits, axis=1) # [batch_size, 10, 16, 1]\n",
    "\n",
    "#the length of each vectors in the digit capsule layer\n",
    "v_lengths = tf.sqrt(tf.reduce_sum(tf.square(digits), axis=2, keepdims=True) + epsilon) #[batch_size, 10, 1, 1]\n",
    "\n",
    "#Objective function for classification\n",
    "max_l = tf.square(tf.maximum(0., m_plus - v_lengths))\n",
    "max_r = tf.square(tf.maximum(0., v_lengths - m_minus))\n",
    "\n",
    "max_l = tf.reshape(max_l, shape=(tf.shape(digits)[0], -1))\n",
    "max_r = tf.reshape(max_r, shape=(tf.shape(digits)[0], -1))\n",
    "T_c = Y\n",
    "\n",
    "L_c = T_c * max_l + lambda_*(1-T_c)*max_r\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1)) #test without reduce mean later\n",
    "\n",
    "\n",
    "#RECONSTRUCTION\n",
    "#First step is to mask out all the vectors from digit capsules except the correct class vector.\n",
    "#By performing an element-wise multiplication between the 10 capsules and the Y vector\n",
    "mask = tf.multiply(tf.squeeze(digits), tf.reshape(Y, (-1, num_labels, 1)))\n",
    "vector_j = tf.reshape(mask, shape=(tf.shape(digits)[0], 160)) #reshape into [batch_size, 160]\n",
    "fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "decoded = tf.contrib.layers.fully_connected(fc2, num_outputs=height*width*1, activation_fn=tf.sigmoid)\n",
    "\n",
    "#RECONSTUCTION LOSS\n",
    "origin   = tf.reshape(X, shape=(tf.shape(digits)[0], -1))\n",
    "squared  = tf.square(decoded - origin)\n",
    "reconst_err = tf.reduce_mean(squared)\n",
    "\n",
    "total_loss = margin_loss + reg_scale + reconst_err #total for both classification and reconstruction\n",
    "\n",
    "optimizer_classification = tf.train.AdamOptimizer(learning_rate).minimize(margin_loss) #for classification\n",
    "optimizer_decoder = tf.train.AdamOptimizer(learning_rate).minimize(total_loss) #for reconstruction\n",
    "\n",
    "softmax_v = tf.nn.softmax(v_lengths, axis=1)\n",
    "argmax_idx = tf.argmax(softmax_v, axis=1)\n",
    "argmax_idx = tf.reshape(argmax_idx, shape=(tf.shape(conv2)[0],))\n",
    "correct_prediction = tf.equal(argmax_idx, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training & Testing Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:44<00:00,  2.32it/s]\n",
      "100%|██████████| 200/200 [00:24<00:00,  8.04it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss 52.7136, training accuracy 0.966033\n",
      "Epoch 0, test loss     1.12137, test accuracy     0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:39<00:00,  2.37it/s]\n",
      "100%|██████████| 200/200 [00:24<00:00,  8.47it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss 14.8451, training accuracy 0.99075\n",
      "Epoch 1, test loss     0.345918, test accuracy     0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:41<00:00,  2.46it/s]\n",
      "100%|██████████| 200/200 [00:23<00:00,  8.27it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, training loss 9.29645, training accuracy 0.9946\n",
      "Epoch 2, test loss     0.157562, test accuracy     0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:40<00:00,  2.49it/s]\n",
      "100%|██████████| 200/200 [00:23<00:00,  9.13it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, training loss 6.21727, training accuracy 0.996967\n",
      "Epoch 3, test loss     0.0430649, test accuracy     0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:19<00:00,  2.40it/s]\n",
      "100%|██████████| 200/200 [00:23<00:00,  8.34it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, training loss 4.20058, training accuracy 0.998167\n",
      "Epoch 4, test loss     0.0328428, test accuracy     0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:43<00:00,  2.39it/s]\n",
      "100%|██████████| 200/200 [00:23<00:00,  9.07it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, training loss 2.83615, training accuracy 0.998733\n",
      "Epoch 5, test loss     0.039404, test accuracy     0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:15<00:00,  2.47it/s]\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.57it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, training loss 1.99332, training accuracy 0.999233\n",
      "Epoch 6, test loss     0.00728982, test accuracy     0.9935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:10<00:00,  2.50it/s]\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.93it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, training loss 1.57387, training accuracy 0.999467\n",
      "Epoch 7, test loss     0.0681656, test accuracy     0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:41<00:00,  2.18it/s]\n",
      "100%|██████████| 200/200 [00:25<00:00,  7.59it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, training loss 1.32704, training accuracy 0.999667\n",
      "Epoch 8, test loss     0.0137066, test accuracy     0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:54<00:00,  2.21it/s]\n",
      "100%|██████████| 200/200 [00:25<00:00,  7.82it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, training loss 1.064, training accuracy 0.999717\n",
      "Epoch 9, test loss     0.00112724, test accuracy     0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [08:45<00:00,  2.28it/s]\n",
      "100%|██████████| 200/200 [00:24<00:00,  6.97it/s]\n",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, training loss 0.933205, training accuracy 0.9998\n",
      "Epoch 10, test loss     0.00343827, test accuracy     0.9943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 164/1200 [01:08<07:29,  2.31it/s]"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_images = images.shape[0] #total number of training images\n",
    "total_test_images = test_images.shape[0] #total number of testing images\n",
    "\n",
    "for epoch_iter in range(epoch):\n",
    "    counter = 0\n",
    "    loss = 0\n",
    "    accuracy_total = 0\n",
    "    test_counter = 0\n",
    "    test_accuracy_total = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    #FOR TRAINING \n",
    "    for index in tqdm(range(0, total_images, batch_size)):\n",
    "        \n",
    "        end_batch = index + batch_size \n",
    "        \n",
    "        if end_batch >= total_images : end_batch = None #to prevent the last index to go beyond the data size\n",
    "        \n",
    "        if reconstruction:\n",
    "            #optimize for classification and reconstruction\n",
    "            loss_, accuracy_,_ = sess.run([total_loss,accuracy, optimizer_decoder], \n",
    "                            feed_dict={X:images[index:end_batch], Y:labels[index:end_batch]})\n",
    "            \n",
    "            loss += loss_\n",
    "            accuracy_total += accuracy_\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        else:\n",
    "            #optimize only for classification\n",
    "            \n",
    "            loss_, accuracy_,_ = sess.run([margin_loss, accuracy, optimizer_classification], \n",
    "                            feed_dict={X:images[index:end_batch], Y:labels[index:end_batch]})\n",
    "            \n",
    "            loss += loss_\n",
    "            accuracy_total += accuracy_\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "    #FOR TESTING\n",
    "    for test_index in tqdm(range(0, total_test_images, batch_size)):\n",
    "        \n",
    "        end_batch_test = test_index + batch_size \n",
    "        \n",
    "        if end_batch_test >= total_test_images : end_batch_test = None #to prevent the last index to go beyond the data size\n",
    "        \n",
    "        if reconstruction:\n",
    "           \n",
    "            test_loss_, test_accuracy_ = sess.run([total_loss,accuracy], \n",
    "                            feed_dict={X:test_images[test_index:end_batch_test], Y:test_labels[test_index:end_batch_test]})\n",
    "            \n",
    "            test_loss += test_loss_\n",
    "            test_accuracy_total += test_accuracy_\n",
    "            \n",
    "            test_counter += 1\n",
    "            \n",
    "        else:\n",
    "          \n",
    "            \n",
    "            test_loss_, test_accuracy_= sess.run([margin_loss, accuracy], \n",
    "                            feed_dict={X:test_images[test_index:end_batch_test], Y:test_labels[test_index:end_batch_test]})\n",
    "            \n",
    "            test_loss += loss_\n",
    "            test_accuracy_total += test_accuracy_\n",
    "            \n",
    "            test_counter += 1\n",
    "        \n",
    "    \n",
    "    print(\"Epoch %d, training loss %g, training accuracy %g\"%(epoch_iter, loss, accuracy_total/counter))\n",
    "    print(\"Epoch %d, test loss     %g, test accuracy     %g\"%(epoch_iter, test_loss, test_accuracy_total/test_counter))\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa",
   "language": "python",
   "name": "nasa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
